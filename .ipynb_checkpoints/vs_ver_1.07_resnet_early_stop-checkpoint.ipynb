{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse,os,time\n",
    "import os\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "num_gpus=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_augmented_split.csv', index_col=0)\n",
    "val_data=pd.read_csv('val_augmented_split.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=data[\"digit\"].values\n",
    "y_data_val=val_data[\"digit\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81900,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=data.loc[:,\"0\":\"783\"].values\n",
    "x_data_val=val_data.loc[:,\"0\":\"783\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81900, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_train=x_data\n",
    "x_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20500, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_test=x_data_val\n",
    "x_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81900, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_train=x_data_train/x_data_train.max()\n",
    "x_data_test=x_data_test/x_data_test.max()\n",
    "x_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,x_dat,y_dat):\n",
    "        x = x_dat\n",
    "        y = y_dat\n",
    "        self.len = x.shape[0]\n",
    "        y=y.astype('int')\n",
    "        x=x.astype('float32')\n",
    "        self.x_data = torch.tensor(x)\n",
    "        self.y_data = torch.tensor(y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_dataset = CustomDataset(x_data_train,y_data)\n",
    "train_loader = DataLoader(dataset=train_dataset,pin_memory=True,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=60,drop_last=True)\n",
    "test_dataset = CustomDataset(x_data_test,y_data_val)\n",
    "test_loader = DataLoader(dataset=test_dataset,pin_memory=True,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=60,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=1\n",
    "# model=Model()\n",
    "# model(train_dataset.x_data[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer_1 = nn.Conv2d(in_channels=1,out_channels=128,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_1 = nn.ReLU()\n",
    "        \n",
    "        self.layer_2 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_2 = nn.ReLU()\n",
    "        \n",
    "        self.layer_3 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_3 = nn.ReLU()\n",
    "        \n",
    "        self.layer_4 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_4 = nn.ReLU()\n",
    "\n",
    "        self.layer_5 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_5 = nn.ReLU()\n",
    "        \n",
    "        self.max_1=nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.layer_6 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_6 = nn.ReLU()\n",
    "        \n",
    "        self.layer_7 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_7 = nn.ReLU()\n",
    "        \n",
    "        self.max_2=nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.layer_8 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=1,\n",
    "                                 stride=1)\n",
    "        self.act_8 = nn.ReLU()\n",
    "        \n",
    "        self.layer_9 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_9 = nn.ReLU()\n",
    "        \n",
    "        self.layer_10 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_10 = nn.ReLU()\n",
    "        \n",
    "\n",
    "        \n",
    "        self.fc_layer_1 = nn.Linear(225*256,1000)\n",
    "        self.act_11 = nn.ReLU()\n",
    "        \n",
    "        self.bnm1=nn.BatchNorm1d(1000)\n",
    "        \n",
    "        self.fc_layer_2 = nn.Linear(1000,10)\n",
    "        self.act_12 = nn.ReLU()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(batch_size//num_gpus,1,28,28)\n",
    "        out = self.layer_1(x)\n",
    "        out = self.act_1(out)\n",
    "        for module in list(self.modules())[2:-5]:\n",
    "            out = module(out)\n",
    "        out = out.view(batch_size//num_gpus,-1)\n",
    "        for module in list(self.modules())[-5:]:\n",
    "            out = module(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.DataParallel(Model().cuda())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/09/10 22:55:44\n",
      "epoch: 1/100 | trn loss: 1.3598 | val loss: 0.8451 | val accuracy: 70.9521% \n",
      "\n",
      "2020/09/10 22:56:36\n",
      "epoch: 2/100 | trn loss: 0.6072 | val loss: 0.6080 | val accuracy: 79.2578% \n",
      "\n",
      "2020/09/10 22:57:27\n",
      "epoch: 3/100 | trn loss: 0.3864 | val loss: 0.4266 | val accuracy: 85.6201% \n",
      "\n",
      "2020/09/10 22:58:18\n",
      "epoch: 4/100 | trn loss: 0.2584 | val loss: 0.3828 | val accuracy: 87.4854% \n",
      "\n",
      "2020/09/10 22:59:07\n",
      "epoch: 5/100 | trn loss: 0.1732 | val loss: 0.3753 | val accuracy: 88.2324% \n",
      "\n",
      "2020/09/10 22:59:57\n",
      "epoch: 6/100 | trn loss: 0.1143 | val loss: 0.3191 | val accuracy: 90.5273% \n",
      "\n",
      "2020/09/10 23:00:46\n",
      "epoch: 7/100 | trn loss: 0.0808 | val loss: 0.3110 | val accuracy: 91.4355% \n",
      "\n",
      "2020/09/10 23:01:36\n",
      "epoch: 8/100 | trn loss: 0.0599 | val loss: 0.3223 | val accuracy: 91.4697% \n",
      "\n",
      "2020/09/10 23:02:26\n",
      "epoch: 9/100 | trn loss: 0.0452 | val loss: 0.3168 | val accuracy: 91.9580% \n",
      "\n",
      "2020/09/10 23:03:15\n",
      "epoch: 10/100 | trn loss: 0.0354 | val loss: 0.3240 | val accuracy: 92.2559% \n",
      "\n",
      "2020/09/10 23:04:04\n",
      "epoch: 11/100 | trn loss: 0.0323 | val loss: 0.3290 | val accuracy: 91.9287% \n",
      "\n",
      "2020/09/10 23:04:53\n",
      "epoch: 12/100 | trn loss: 0.0263 | val loss: 0.3551 | val accuracy: 92.3340% \n",
      "\n",
      "2020/09/10 23:05:43\n",
      "epoch: 13/100 | trn loss: 0.0284 | val loss: 0.3552 | val accuracy: 91.9775% \n",
      "\n",
      "Early stop!\n"
     ]
    }
   ],
   "source": [
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "total_epoch=100\n",
    "\n",
    "patience=5\n",
    "start_early_stop_check=0\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        mis_match = 0\n",
    "        for j, val in enumerate(test_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            mis_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(test_loader))\n",
    "    val_acc=mis_match/(len(test_loader)*batch_size)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(test_loader), val_acc*100\n",
    "            ))     \n",
    "    if epoch>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved complete\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"model_ver-1.07\")\n",
    "print(\"model saved complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
